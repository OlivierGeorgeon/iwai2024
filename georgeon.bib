
@misc{lanillos_active_2021,
	title = {Active Inference in Robotics and Artificial Agents: Survey and Challenges},
	url = {http://arxiv.org/abs/2112.01871},
	doi = {10.48550/arXiv.2112.01871},
	shorttitle = {Active Inference in Robotics and Artificial Agents},
	abstract = {Active inference is a mathematical framework which originated in computational neuroscience as a theory of how the brain implements action, perception and learning. Recently, it has been shown to be a promising approach to the problems of state-estimation and control under uncertainty, as well as a foundation for the construction of goal-driven behaviours in robotics and artificial agents in general. Here, we review the state-of-the-art theory and implementations of active inference for state-estimation, control, planning and learning; describing current achievements with a particular focus on robotics. We showcase relevant experiments that illustrate its potential in terms of adaptation, generalization and robustness. Furthermore, we connect this approach with other frameworks and discuss its expected benefits and challenges: a unified framework with functional biological plausibility using variational Bayesian inference.},
	number = {{arXiv}:2112.01871},
	publisher = {{arXiv}},
	author = {Lanillos, Pablo and Meo, Cristian and Pezzato, Corrado and Meera, Ajith Anil and Baioumy, Mohamed and Ohata, Wataru and Tschantz, Alexander and Millidge, Beren and Wisse, Martijn and Buckley, Christopher L. and Tani, Jun},
	urldate = {2024-02-28},
	date = {2021-12-03},
	eprinttype = {arxiv},
	eprint = {2112.01871 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Robotics},
	file = {arXiv Fulltext PDF:C\:\\Users\\ogeorgeon\\Zotero\\storage\\WZIE5RKI\\Lanillos et al. - 2021 - Active Inference in Robotics and Artificial Agents.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\ogeorgeon\\Zotero\\storage\\UJEDW964\\2112.html:text/html},
}

@article{battaglia_simulation_2013,
	title = {Simulation as an engine of physical scene understanding},
	volume = {110},
	doi = {10.1073/pnas.1306572110},
	pages = {18327--18332},
	number = {45},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Battaglia, Peter W. and Hamrick, Jessica B. and Tenenbaum, Joshua B.},
	year = {2013},
	publisher = {Proceedings of the National Academy of Sciences},
}

@article{ullman_mind_2017,
	title = {Mind Games: Game Engines as an Architecture for Intuitive Physics},
	volume = {21},
	issn = {13646613},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1364661317301134},
	doi = {10.1016/j.tics.2017.05.012},
	shorttitle = {Mind Games},
	pages = {649--665},
	number = {9},
	journaltitle = {Trends in Cognitive Sciences},
	shortjournal = {Trends in Cognitive Sciences},
	author = {Ullman, Tomer D. and Spelke, Elizabeth and Battaglia, Peter and Tenenbaum, Joshua B.},
	urldate = {2024-03-01},
	date = {2017-09},
	langid = {english},
	file = {Ullman et al. - 2017 - Mind Games Game Engines as an Architecture for In.pdf:C\:\\Users\\ogeorgeon\\Zotero\\storage\\STHQEWFJ\\Ullman et al. - 2017 - Mind Games Game Engines as an Architecture for In.pdf:application/pdf},
}

@inproceedings{helvik_using_2001,
	location = {Berlin, Heidelberg},
	title = {Using the Cross-Entropy Method to Guide/Govern Mobile Agent’s Path Finding in Networks},
	isbn = {978-3-540-44651-4},
	doi = {10.1007/3-540-44651-6_24},
	series = {Lecture Notes in Computer Science},
	abstract = {The problem of finding paths in networks is general and many faceted with a wide range of engineering applications in communication networks. Finding the optimal path or combination of paths usually leads to {NP}-hard combinatorial optimization problems. A recent and promising method, the cross-entropy method proposed by Rubinstein, manages to produce optimal solutions to such problems in polynomial time. However this algorithm is centralized and batch oriented. In this paper we show how the cross-entropy method can be reformulated to govern the behaviour of multiple mobile agents which act independently and asynchronously of each other. The new algorithm is evaluate on a set of well known Travelling Salesman Problems. A simulator, based on the Network Simulator package, has been implemented which provide realistic simulation environments. Results show good performance and stable convergence towards near optimal solution of the problems tested.},
	pages = {255--268},
	booktitle = {Mobile Agents for Telecommunication Applications},
	publisher = {Springer},
	author = {Helvik, Bjarne E. and Wittner, Otto},
	editor = {Pierre, Samuel and Glitho, Roch},
	date = {2001},
	langid = {english},
	keywords = {Destination Node, Mobile Agent, Optimal Path, Tabu Search, Travel Salesman Problem},
	file = {Full Text PDF:C\:\\Users\\ogeorgeon\\Zotero\\storage\\X927ZHKU\\Helvik et Wittner - 2001 - Using the Cross-Entropy Method to GuideGovern Mob.pdf:application/pdf},
}

@article{de_boer_tutorial_2005,
	title = {A Tutorial on the Cross-Entropy Method},
	volume = {134},
	issn = {0254-5330, 1572-9338},
	url = {http://link.springer.com/10.1007/s10479-005-5724-z},
	doi = {10.1007/s10479-005-5724-z},
	abstract = {The cross-entropy ({CE}) method is a new generic approach to combinatorial and multi-extremal optimization and rare event simulation. The purpose of this tutorial is to give a gentle introduction to the {CE} method. We present the {CE} methodology, the basic algorithm and its modiﬁcations, and discuss applications in combinatorial optimization and machine learning.},
	pages = {19--67},
	number = {1},
	journaltitle = {Annals of Operations Research},
	shortjournal = {Ann Oper Res},
	author = {De Boer, Pieter-Tjerk and Kroese, Dirk P. and Mannor, Shie and Rubinstein, Reuven Y.},
	urldate = {2024-03-03},
	date = {2005-02},
	langid = {english},
	file = {De Boer et al. - 2005 - A Tutorial on the Cross-Entropy Method.pdf:C\:\\Users\\ogeorgeon\\Zotero\\storage\\JVQSE4S9\\De Boer et al. - 2005 - A Tutorial on the Cross-Entropy Method.pdf:application/pdf},
}


@misc{petitcat_github,
	title = {PetitCat project repository},
	url = {https://github.com/UCLy/INIT2/},
	urldate = {2024-02-27},
	journal = {osoyoo.com},
	author = {Georgeon, Olivier L.},
	year = {2024},
}

@misc{osoyoo_robot_car,
	title = {M2.0 Metal Chassis Mecanum Wheel Robotic},
	url = {https://osoyoo.com/2022/07/05/v2-metal-chassis-mecanum-wheel-robotic-for-arduino-mega2560-introduction-model-2021006600/},
	urldate = {2024-02-27},
	journal = {osoyoo.com},
	author = {Osoyoo},
	year = {2022},
}

@article{friston_free-energy_2010,
	title = {The free-energy principle: a unified brain theory?},
	volume = {11},
	issn = {1471-0048},
	doi = {10.1038/nrn2787},
	pages = {127--138},
	number = {2},
	journal = {Nature Reviews Neuroscience},
	author = {Friston, Karl},
	date = {2010-02},
	year = {2010},
}

@article{smith_step-by-step_2022,
	title = {A step-by-step tutorial on active inference and its application to empirical data},
	volume = {107},
	issn = {0022-2496},
	doi = {10.1016/j.jmp.2021.102632},
	pages = {102632},
	journal = {Journal of Mathematical Psychology},
	author = {Smith, Ryan and Friston, Karl J. and Whyte, Christopher J.},
	date = {2022-04-01},
	year = {2022},
}


@book{thorisson_explanation_2021,
	title = {The `{Explanation} {Hypothesis}' in general self-supervised {Learning}},
	publisher = {International Workshop in Self-Supervised Learning},
	author = {Thórisson, Kristinn R.},
	year = {2021},
}

@inproceedings{georgeon_interactional_2012,
	location = {San Diego, {CA}, {USA}},
	title = {Interactional Motivation in artificial systems: Between extrinsic and intrinsic motivation},
	isbn = {978-1-4673-4965-9 978-1-4673-4964-2 978-1-4673-4963-5},
	doi = {10.1109/DevLrn.2012.6400833},
	eventtitle = {2012 {IEEE} International Conference on Development and Learning and Epigenetic Robotics ({ICDL})},
	booktitle = {{IEEE} International Conference on Development and Learning and Epigenetic Robotics ({ICDL})},
	pages = {1--2},
	publisher = {{IEEE}},
	author = {Georgeon, Olivier L. and Marshall, James B. and Gay, Simon},
	date = {2012-11},
	year = {2012},
}

@audio{fridman_joscha_nodate,
	title = {Joscha Bach: Life, Intelligence, Consciousness, {AI} \& the Future of Humans},
	url = {https://youtu.be/e8qJsk1j2zE},
	number = {392},
	author = {Fridman, Lex},
	urldate = {2023-08-17},
	year = {2023},
}
@article{buzsaki_memory_2013,
	title = {Memory, navigation and theta rhythm in the hippocampal-entorhinal system},
	volume = {16},
	doi = {10.1038/nn.3304},
	pages = {130--138},
	number = {2},
	journaltitle = {Nature Neuroscience},
	journal = {Nature Neuroscience},
	author = {Buzsáki, György and Moser, Edvard I},
	date = {2013},
	year = {2013},
	langid = {english},
}
@inproceedings{robertson_biologically_2009,
	title = {A biologically inspired spatial computer that learns to see and act},
	copyright = {All rights reserved},
	booktitle = {Spatial {Computing} {Workshop}, {SASO} 2009, {San} {Francisco}},
	author = {Robertson, Paul and Laddaga, Robert},
	year = {2009},
}
@article{gottlieb_towards_2018,
	title = {Towards a neuroscience of active sampling and curiosity},
	volume = {19},
	issn = {1471-0048},
	doi = {10.1038/s41583-018-0078-0},
	abstract = {In natural behaviour, animals actively interrogate their environments using endogenously generated 'question-and-answer' strategies. However, in laboratory settings participants typically engage with externally imposed stimuli and tasks, and the mechanisms of active sampling remain poorly understood. We review a nascent neuroscientific literature that examines active-sampling policies and their relation to attention and curiosity. We distinguish between information sampling, in which organisms reduce uncertainty relevant to a familiar task, and information search, in which they investigate in an open-ended fashion to discover new tasks. We review evidence that both sampling and search depend on individual preferences over cognitive states, including attitudes towards uncertainty, learning progress and types of information. We propose that, although these preferences are non-instrumental and can on occasion interfere with external goals, they are important heuristics that allow organisms to cope with the high complexity of both sampling and search, and generate curiosity-driven investigations in large, open environments in which rewards are sparse and ex ante unknown.},
	language = {eng},
	number = {12},
	journal = {Nature Reviews. Neuroscience},
	author = {Gottlieb, Jacqueline and Oudeyer, Pierre-Yves},
	month = dec,
	year = {2018},
	pmid = {30397322},
	keywords = {Humans, Animals, Attention, Brain, Cognition, Exploratory Behavior, Neurosciences, Reward},
	pages = {758--770},
}

@article{astrom1965optimal,
title={Optimal control of Markov processes with incomplete state information},
author={{\AA}str{\"o}m, Karl Johan},
journal={Journal of mathematical analysis and applications},
volume={10},
number={1},
pages={174--205},
year={1965},
publisher={Academic Press}
}

@article{maye_extending_2013,
	title = {Extending sensorimotor contingency theory: prediction, planning, and action generation},
	volume = {21},
	issn = {1059-7123},
	doi = {10.1177/1059712313497975},
	pages = {423--436},
	number = {6},
	journaltitle = {Adaptive Behavior},
	journal = {Adaptive Behavior},
	author = {Maye, Alexander and Engel, Andreas K},
	date = {2013},
	year = {2013},
}
@book{hutto_radicalizing_2013,
	title = {Radicalizing Enactivism: Basic Minds Without Content},
	publisher = {Cambridge, {MA}: {MIT} Press},
	author = {Hutto, Daniel D. and Myin, Erik},
	year = {2013},
}

@book{varela_embodied_1993,
	location = {Cambridge, Mass.},
	edition = {14. print.},
	title = {The embodied mind: cognitive science and human experience},
	isbn = {978-0-262-72021-2},
	pagetotal = {308},
	publisher = {{MIT} Press},
	author = {Varela, Francisco J. and Thompson, Evan and Rosch, Eleanor},
	date = {1993},
	year = {1993},
}
@article{friston_world_2021,
	title = {World model learning and inference},
	volume = {144},
	issn = {0893-6080},
	doi = {10.1016/j.neunet.2021.09.011},
	pages = {573--590},
	journaltitle = {Neural Networks},
	journal = {Neural Networks},
	author = {Friston, Karl and Moran, Rosalyn J. and Nagai, Yukie and Taniguchi, Tadahiro and Gomi, Hiroaki and Tenenbaum, Josh},
	year = {2021},
}
@article{oregan_sensorimotor_2001,
	title = {A sensorimotor account of vision and visual consciousness},
	volume = {24},
	issn = {0140-525X, 1469-1825},
	doi = {10.1017/S0140525X01000115},
	pages = {939--973},
	number = {5},
	journaltitle = {Behavioral and Brain Sciences},
	journal = {Behavioral and Brain Sciences},
	author = {O'Regan, J. Kevin and Noë, Alva},
	year = {2001},
}
@article{laming_distinction_2001,
	title = {On the distinction between ``sensorimotor'' and ``motorsensory'' contingencies},
	volume = {24},
	issn = {0140-525X, 1469-1825},
	doi = {10.1017/S0140525X01430111},
	pages = {992--992},
	number = {5},
	journaltitle = {Behavioral and Brain Sciences},
	author = {Laming, Donald},
	year = {2001},
}
@article{oudeyer_intrinsic_2007,
	title = {Intrinsic motivation systems for autonomous mental development},
	volume = {11},
	issn = {1089-778X},
	doi = {10.1109/TEVC.2006.890271},
	pages = {265--286},
	number = {2},
	journaltitle = {{IEEE} Transactions on Evolutionary Computation},
	author = {Oudeyer, Pierre-Yves and Kaplan, Frdric and Hafner, Verena V.},
	date = {2007-04},
}
@article{hauskrecht_value-function_2000,
	title = {Value-Function Approximations for Partially Observable Markov Decision Processes},
	volume = {13},
	issn = {1076-9757},
	doi = {10.1613/jair.678},
	pages = {33--94},
	journaltitle = {Journal of Artificial Intelligence Research},
	author = {Hauskrecht, M.},
	date = {2000-08-01},
}

@book{howard1984readings,
title={Readings on the Principles and Applications of Decision Analysis: Professional Collection},
author={Howard, Ronald Arthur},
volume={2},
year={1984},
publisher={Strategic Decisions Group}
}

@inproceedings{cassandra1998survey,
title={A survey of POMDP applications},
author={Cassandra, Anthony R},
booktitle={Working notes of AAAI 1998 fall symposium on planning with partially observable Markov decision processes},
volume={1724},
year={1998}
}

@article{renault2010uniform,
title={Uniform value in dynamic programming},
author={Renault, J{\'e}r{\^o}me},
journal={Journal of the European Mathematical Society},
volume={13},
number={2},
pages={309--330},
year={2010}
}

@article{renault2017long,
title={Long-term values in Markov decision processes and repeated games, and a new distance for probability spaces},
author={Renault, J{\'e}r{\^o}me and Venel, Xavier},
journal={Mathematics of Operations Research},
volume={42},
number={2},
pages={349--376},
year={2017},
publisher={INFORMS}
}

@article{rosenberg2002blackwell,
title={Blackwell optimality in Markov decision processes with partial observation},
author={Rosenberg, Dinah and Solan, Eilon and Vieille, Nicolas},
journal={Annals of statistics},
pages={1178--1193},
year={2002},
publisher={JSTOR}
}


@article{venel2016strong,
title={Strong uniform value in gambling houses and partially observable Markov decision processes},
author={Venel, Xavier and Ziliotto, Bruno},
journal={SIAM Journal on Control and Optimization},
volume={54},
number={4},
pages={1983--2008},
year={2016},
publisher={SIAM}
}

@article{smallwood1973optimal,
title={The optimal control of partially observable Markov processes over a finite horizon},
author={Smallwood, Richard D and Sondik, Edward J},
journal={Operations research},
volume={21},
number={5},
pages={1071--1088},
year={1973},
publisher={INFORMS}
}

@book{pearl1988probabilistic,
title={Probabilistic reasoning in intelligent systems: networks of plausible inference},
author={Pearl, Judea},
year={1988},
publisher={Morgan kaufmann}
}

@article{dean1989model,
title={A model for reasoning about persistence and causation},
author={Dean, Thomas and Kanazawa, Keiji},
journal={Computational intelligence},
volume={5},
number={2},
pages={142--150},
year={1989},
publisher={Wiley Online Library}
}

@book{poupart2005exploiting,
title={Exploiting structure to efficiently solve large scale partially observable Markov decision processes},
author={Poupart, Pascal},
year={2005},
publisher={Citeseer}
}


@article{friedman1997bayesian,
title={Bayesian network classifiers},
author={Friedman, Nir and Geiger, Dan and Goldszmidt, Moises},
journal={Machine learning},
volume={29},
pages={131--163},
year={1997},
publisher={Springer}
}

@article{ben2008bayesian,
title={Bayesian networks},
author={Ben-Gal, Irad},
journal={Encyclopedia of statistics in quality and reliability},
volume={1},
year={2008},
publisher={Wiley Online Library}
}

@article{chatterjee2016decidable,
title={What is decidable about partially observable Markov decision processes with $\omega$-regular objectives},
author={Chatterjee, Krishnendu and Chmelik, Martin and Tracol, Mathieu},
journal={Journal of Computer and System Sciences},
volume={82},
number={5},
pages={878--911},
year={2016},
publisher={Elsevier}
}

@article{chatterjee2022finite,
title={Finite-memory strategies in pomdps with long-run average objectives},
author={Chatterjee, Krishnendu and Saona, Raimundo and Ziliotto, Bruno},
journal={Mathematics of Operations Research},
volume={47},
number={1},
pages={100--119},
year={2022},
publisher={INFORMS}
}

@article{lee2007makes,
title={What makes some POMDP problems easy to approximate?},
author={Lee, Wee and Rong, Nan and Hsu, David},
journal={Advances in neural information processing systems},
volume={20},
year={2007}
}

@article{murphy1998brief,
title={A brief introduction to graphical models and bayesian networks, 1998},
author={Murphy, Kevin},
journal={Available electronically at http://www. cs. ubc. ca/~ murphyk/Bayes/bnintro. html},
year={1998}
}

@article{kaelbling1998planning,
title={Planning and acting in partially observable stochastic domains},
author={Kaelbling, Leslie Pack and Littman, Michael L and Cassandra, Anthony R},
journal={Artificial intelligence},
volume={101},
number={1-2},
pages={99--134},
year={1998},
publisher={Elsevier}
}

@article{pineau2006anytime,
title={Anytime point-based approximations for large POMDPs},
author={Pineau, Joelle and Gordon, Geoffrey and Thrun, Sebastian},
journal={Journal of Artificial Intelligence Research},
volume={27},
pages={335--380},
year={2006}
}

@article{papadimitriou1987complexity,
title={The complexity of Markov decision processes},
author={Papadimitriou, Christos H and Tsitsiklis, John N},
journal={Mathematics of operations research},
volume={12},
number={3},
pages={441--450},
year={1987},
publisher={INFORMS}
}

@inproceedings{madani1999undecidability,
title={On the undecidability of probabilistic planning and infinite-horizon partially observable Markov decision problems},
author={Madani, Omid and Hanks, Steve and Condon, Anne},
booktitle={AAAI/IAAI},
pages={541--548},
year={1999}
}

@article{dagum1993approximating,
title={Approximating probabilistic inference in Bayesian belief networks is NP-hard},
author={Dagum, Paul and Luby, Michael},
journal={Artificial intelligence},
volume={60},
number={1},
pages={141--153},
year={1993},
publisher={Elsevier}
}

@article{cooper1990computational,
title={The computational complexity of probabilistic inference using Bayesian belief networks},
author={Cooper, Gregory F},
journal={Artificial intelligence},
volume={42},
number={2-3},
pages={393--405},
year={1990},
publisher={Elsevier}
}

@article{hawkins_framework_2019,
    title = {A Framework for Intelligence and Cortical Function Based on Grid Cells in the Neocortex},
    author = {Hawkins, Jeff and Lewis, Marcus and Klukas, Mirko and Purdy, Scott and Ahmad, Subutai},
    journaltitle = {Frontiers in Neural Circuits},
    journal = {Frontiers in Neural Circuits},
    volume = {12},
    issn = {1662-5110},
    date = {2019},
    year = {2019},
}

@article{gay_autonomous_2017,
    title = {Autonomous construction and exploitation of a spatial memory by a self-motivated agent},
    volume = {41},
    issn = {13890417},
    doi = {10.1016/j.cogsys.2016.07.004},
    pages = {1--35},
    journaltitle = {Cognitive Systems Research},
    journal = {Cognitive Systems Research},
    shortjournal = {Cognitive Systems Research},
    author = {Gay, Simon L. and Mille, Alain and Georgeon, Olivier L. and Dutech, Alain},
    urldate = {2021-09-18},
    date = {2017-03},
    year = {2017},
    langid = {english},
}
@misc{georgeon_slapi_2023,
    title = {The shark experiment},
    url = {https://youtu.be/vSUEoh-sjwU},
    urldate = {2023-04-17},
    journal = {Youtube},
    author = {Georgeon, Olivier L.},
    year = {2023},
}
@misc{georgeon_video_2023,
	title = {Robot exploring the arena},
	url = {https://youtu.be/rKYiXNGiyiE},
	urldate = {2023-04-17},
	journal = {Youtube},
	author = {Georgeon, Olivier L.},
	year = {2023},
}
@misc{mordvintsev2022diff_fsm,
    author = {Mordvintsev, Alexander},
    title = {Differentiable Finite State Machines},
    url = {https://google-research.github.io/self-organising-systems/2022/diff-fsm/},
    year = {2022},
    urldate = {2023-04-10},
}
@inproceedings{woolford_precarious_2020,
    title = {A Precarious Sensorimotor Sequence Reiterator for Modelling Enactive Habits},
    doi = {10.1162/isal\_a\_00249},
    eventtitle = {{ALIFE} 2020: The 2020 Conference on Artificial Life},
    booktitle = {{ALIFE} 2020: The 2020 Conference on Artificial Life},
    pages = {771--779},
    publisher = {{MIT} Press},
    author = {Woolford, Felix M. G. and Egbert, Matthew D.},
    date = {2020-07-01},
    year = {2020},
    langid = {english},
}

@article{froese_enactive_2009,
    title = {Enactive artificial intelligence: Investigating the systemic organization of life and mind},
    volume = {173},
    issn = {00043702},
    doi = {10.1016/j.artint.2008.12.001},
    shorttitle = {Enactive artificial intelligence},
    pages = {466--500},
    number = {3},
    journaltitle = {Artificial Intelligence},
    shortjournal = {Artificial Intelligence},
    author = {Froese, Tom and Ziemke, Tom},
    date = {2009-03},
    langid = {english},
}

@InProceedings{pmlr-v192-georgeon22a,
    title =      {Simultaneous Localization and Active Phenomenon Inference {(SLAPI)}},
    author =       {Georgeon, Olivier L. and Vidal, Juan R. and Knockaert, Titouan and Robertson, Paul},
    booktitle =      {Proceedings of the Third International Workshop on Self-Supervised Learning},
    pages =      {77--88},
    year =   {2022},
    editor =     {Thórisson, Kristinn R.},
    volume =     {192},
    series =     {Proceedings of Machine Learning Research},
    publisher =    {PMLR},
}

@article{ramstead_tale_2020,
    title = {A tale of two densities: active inference is enactive inference},
    volume = {28},
    issn = {1059-7123},
    number = {4},
    journaltitle = {Adaptive Behavior},
    journal={Adaptive Behavior},
    shortjournal = {Adapt Behav},
    author = {Ramstead, Maxwell Jd and Kirchhoff, Michael D. and Friston, Karl J.},
    date = {2020-08},
    year = {2020},
    pmid = {32831534},
    pmcid = {PMC7418871},
    keywords = {enactivism, Active inference, free-energy principle, representationalism, structural representations},
}

@article{grieves_representation_2017,
    title = {The representation of space in the brain},
    volume = {135},
    issn = {0376-6357},
    doi = {https://doi.org/10.1016/j.beproc.2016.12.012},
    pages = {113--131},
    journaltitle = {Behavioural Processes},
    journal = {Behavioural Processes},
    author = {Grieves, Roddy M. and Jeffery, Kate J.},
    date = {2017},
    year = {2017},
    keywords = {Grid cell, Head direction cell, Navigation, Place cell, Spatial cognition},
}

@article{georgeon_eca_2013,
    title = {{ECA}: An enactivist cognitive architecture based on sensorimotor modeling},
    volume = {6},
    issn = {2212683X},
    doi = {10.1016/j.bica.2013.05.006},
    pages = {46--57},
    journaltitle = {Biologically Inspired Cognitive Architectures},
    journal = {Biologically Inspired Cognitive Architectures},
    author = {Georgeon, Olivier L. and Marshall, James B. and Manzotti, Riccardo},
    date = {2013-10},
    year = {2013},
    langid = {english},
}

@article{kaelbling_planning_1998,
    title = {Planning and acting in partially observable stochastic domains},
    volume = {101},
    issn = {0004-3702},
    doi = {10.1016/S0004-3702(98)00023-X},
    pages = {99--134},
    number = {1},
    journaltitle = {Artificial Intelligence},
    shortjournal = {Artificial Intelligence},
    author = {Kaelbling, Leslie Pack and Littman, Michael L. and Cassandra, Anthony R.},
    date = {1998-05-01},
    langid = {english},
}

@book{pearl_probabilistic_1988,
    title = {Probabilistic reasoning in intelligent systems : networks of plausible inference},
    isbn = {978-0-934613-73-6},
    shorttitle = {Probabilistic reasoning in intelligent systems},
    pagetotal = {586},
    publisher = {San Mateo, Calif. : Morgan Kaufmann Publishers},
    author = {Pearl, Judea},
    editora = {{Internet Archive}},
    editoratype = {collaborator},
    date = {1988},
    year = {1988},
    keywords = {Artificial intelligence},
}

@inproceedings{georgeon_enactive_2013,
    title = {An Enactive approach to autonomous agent and robot learning},
    doi = {10.1109/DevLrn.2013.6652527},
    eventtitle = {2013 {IEEE} Third Joint International Conference on Development and Learning and Epigenetic Robotics ({ICDL})},
    pages = {1--6},
    booktitle = {2013 {IEEE} Third Joint International Conference on Development and Learning and Epigenetic Robotics ({ICDL})},
    author = {Georgeon, Olivier L. and Wolf, Christian and Gay, Simon},
    date = {2013-08},
    year = {2013},
}

@article{spaan_decision-theoretic_2009,
    title = {A Decision-Theoretic Approach to Dynamic Sensor Selection in Camera Networks},
    volume = {19},
    rights = {Copyright (c) 2021 Proceedings of the International Conference on Automated Planning and Scheduling},
    issn = {2334-0843},
    doi = {10.1609/icaps.v19i1.13381},
    abstract = {Nowadays many urban areas have been equipped with networks of surveillance cameras, which can be used for automatic localization and tracking of people. However, given the large resource demands of imaging sensors in terms of bandwidth and computing power, processing the image streams of all cameras simultaneously might not be feasible. In this paper, we consider the problem of dynamical sensor selection based on user-defined objectives, such as maximizing coverage or improved localization uncertainty.  We propose a decision-theoretic approach modeled as a {POMDP}, which selects k sensors to consider in the next time frame, incorporating all observations made in the past. We show how, by changing the {POMDP}'s reward function, we can change the system's behavior in a straightforward manner, fulfilling the user's chosen objective. We successfully apply our techniques to a network of 10 cameras.},
    pages = {297--304},
    journaltitle = {Proceedings of the International Conference on Automated Planning and Scheduling},
    author = {Spaan, Matthijs and Lima, Pedro},
    date = {2009-10-16},
    langid = {english},
    keywords = {Sensor Networks},
}

@article{hansen_integrated_2021,
    title = {An integrated approach to solving influence diagrams and finite-horizon partially observable decision processes},
    volume = {294},
    issn = {0004-3702},
    doi = {10.1016/j.artint.2020.103431},
    abstract = {We show how to integrate a variable elimination approach to solving influence diagrams with a value iteration approach to solving finite-horizon partially observable Markov decision processes ({POMDPs}). The integration of these approaches creates a variable elimination algorithm for influence diagrams that has much more relaxed constraints on elimination order, which allows improved scalability in many cases. The new algorithm can also be viewed as a generalization of the value iteration algorithm for {POMDPs} that solves non-Markovian as well as Markovian problems, in addition to leveraging a factored representation for improved efficiency. The development of a single algorithm that integrates and generalizes both of these classic algorithms, one for influence diagrams and the other for {POMDPs}, unifies these two approaches to solving Bayesian decision problems in a way that combines their complementary advantages.},
    pages = {103431},
    journaltitle = {Artificial Intelligence},
    journal = {Artificial Intelligence},
    shortjournal = {Artificial Intelligence},
    author = {Hansen, Eric A.},
    date = {2021-05-01},
    year = {2021},
    langid = {english},
    keywords = {Decision-theoretic planning, Dynamic programming, Influence diagram, Partially observable Markov decision process, Variable elimination},
}

@article{georgeon_intrinsically-motivated_2012,
    title = {An intrinsically-motivated schema mechanism to model and simulate emergent cognition},
    volume = {15-16},
    issn = {1389-0417},
    doi = {10.1016/j.cogsys.2011.07.003},
    journal = {Cognitive Systems Research},
    author = {Georgeon, Olivier L. and Ritter, Frank E.},
    year = {2012},
    pages = {73--92},
}

@phdthesis{jarraya_siala_nouvelles_2013,
    type = {These de doctorat},
    title = {Nouvelles paramétrisations de réseaux bayésiens et leur estimation implicite : famille exponentielle naturelle et mélange infini de {Gaussiennes}},
    copyright = {Licence Etalab},
    shorttitle = {Nouvelles paramétrisations de réseaux bayésiens et leur estimation implicite},
    url = {https://www.theses.fr/2013NANT2042},
    abstract = {L’apprentissage d’un réseau Bayésien consiste à estimer le graphe (la structure) et les paramètres des distributions de probabilités conditionnelles associées à ce graphe. Les algorithmes d’apprentissage de réseaux Bayésiens utilisent en pratique une approche Bayésienne classique d’estimation a posteriori dont les paramètres sont souvent déterminés par un expert ou définis de manière uniforme Le coeur de cette thèse concerne l’application aux réseaux Bayésiens de plusieurs avancées dans le domaine des Statistiques comme l’estimation implicite, les familles exponentielles naturelles ou les mélanges infinis de lois Gaussiennes dans le but de (1) proposer de nouvelles formes paramétriques, (2) estimer des paramètres de tels modèles et (3) apprendre leur structure},
    urldate = {2023-02-03},
    school = {Nantes},
    author = {Jarraya Siala, Aida},
    collaborator = {Leray, Philippe and Masmoudi, Afif},
    month = jan,
    year = {2013},
    keywords = {Fonctions exponentielles, Processus gaussiens, Statistique bayésienne},
    annote = {Sous la direction de  Philippe Leray et de  Afif Masmoudi. Soutenue en 2013,à Nantes , en partenariat avec  Université de Nantes. Faculté des sciences et des techniques   (autre partenaire)  .},
}

@phdthesis{Kevin_murphy,
  author  = "Kevin Murphy",
  title   = "Dynamic Bayesian Networks: Representation, Inference and Learning",
  school  = "University of California, Berkeley",
  year    = "2002",
  type    = "PhD Thesis",
}

@article{georgeon_cash_2019,
    title = {{CASH} only: {Constitutive} autonomy through motorsensory self-programming},
    volume = {58},
    issn = {1389-0417},
    shorttitle = {{CASH} only},
    doi = {10.1016/j.cogsys.2019.08.006},
    language = {en},
    urldate = {2023-02-07},
    journal = {Cognitive Systems Research},
    author = {Georgeon, Olivier L. and Riegler, Alexander},
    month = dec,
    year = {2019},
    keywords = {Autonomy, Cognitive architectures, Constructivist learning, Enaction, Self-motivation},
    pages = {366--374},
    file = {ScienceDirect Snapshot:files/55/Georgeon and Riegler - 2019 - CASH only Constitutive autonomy through motorsens.html:text/html},
}

@book{spirtes_causation_2012,
    title = {Causation, {Prediction}, and {Search}},
    isbn = {978-1-4612-2748-9},
    abstract = {This book is intended for anyone, regardless of discipline, who is interested in the use of statistical methods to help obtain scientific explanations or to predict the outcomes of actions, experiments or policies. Much of G. Udny Yule's work illustrates a vision of statistics whose goal is to investigate when and how causal influences may be reliably inferred, and their comparative strengths estimated, from statistical samples. Yule's enterprise has been largely replaced by Ronald Fisher's conception, in which there is a fundamental cleavage between experimental and non experimental inquiry, and statistics is largely unable to aid in causal inference without randomized experimental trials. Every now and then members of the statistical community express misgivings about this turn of events, and, in our view, rightly so. Our work represents a return to something like Yule's conception of the enterprise of theoretical statistics and its potential practical benefits. If intellectual history in the 20th century had gone otherwise, there might have been a discipline to which our work belongs. As it happens, there is not. We develop material that belongs to statistics, to computer science, and to philosophy; the combination may not be entirely satisfactory for specialists in any of these subjects. We hope it is nonetheless satisfactory for its purpose.},
    language = {en},
    publisher = {Springer Science \& Business Media},
    author = {Spirtes, Peter and Glymour, Clark and Scheines, Richard},
    month = dec,
    year = {2012},
    note = {Google-Books-ID: oUjxBwAAQBAJ},
    keywords = {Mathematics / Applied, Mathematics / General},
}

@misc{ramsey_adjacency-faithfulness_2012,
    title = {Adjacency-{Faithfulness} and {Conservative} {Causal} {Inference}},
    url = {http://arxiv.org/abs/1206.6843},
    doi = {10.48550/arXiv.1206.6843},
    abstract = {Most causal inference algorithms in the literature (e.g., Pearl (2000), Spirtes et al. (2000), Heckerman et al. (1999)) exploit an assumption usually referred to as the causal Faithfulness or Stability condition. In this paper, we highlight two components of the condition used in constraint-based algorithms, which we call "Adjacency-Faithfulness" and "Orientation-Faithfulness". We point out that assuming Adjacency-Faithfulness is true, it is in principle possible to test the validity of Orientation-Faithfulness. Based on this observation, we explore the consequence of making only the Adjacency-Faithfulness assumption. We show that the familiar PC algorithm has to be modified to be (asymptotically) correct under the weaker, Adjacency-Faithfulness assumption. Roughly the modified algorithm, called Conservative PC (CPC), checks whether Orientation-Faithfulness holds in the orientation phase, and if not, avoids drawing certain causal conclusions the PC algorithm would draw. However, if the stronger, standard causal Faithfulness condition actually obtains, the CPC algorithm is shown to output the same pattern as the PC algorithm does in the large sample limit. We also present a simulation study showing that the CPC algorithm runs almost as fast as the PC algorithm, and outputs significantly fewer false causal arrowheads than the PC algorithm does on realistic sample sizes. We end our paper by discussing how score-based algorithms such as GES perform when the Adjacency-Faithfulness but not the standard causal Faithfulness condition holds, and how to extend our work to the FCI algorithm, which allows for the possibility of latent variables.},
    urldate = {2023-02-07},
    publisher = {arXiv},
    author = {Ramsey, Joseph and Zhang, Jiji and Spirtes, Peter L.},
    month = jun,
    year = {2012},
    note = {arXiv:1206.6843 [cs, stat]},
    keywords = {Computer Science - Artificial Intelligence, Statistics - Methodology},
    annote = {Comment: Appears in Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence (UAI2006)},
    file = {arXiv Fulltext PDF:files/61/Ramsey et al. - 2012 - Adjacency-Faithfulness and Conservative Causal Inf.pdf:application/pdf;arXiv.org Snapshot:files/62/1206.html:text/html},
}

@misc{wang_uniformly_2021,
    title = {A {Uniformly} {Consistent} {Estimator} of non-{Gaussian} {Causal} {Effects} {Under} the k-{Triangle}-{Faithfulness} {Assumption}},
    url = {http://arxiv.org/abs/2107.01333},
    abstract = {Kalisch and Bu¨hlmann (2007) showed that for linear Gaussian models, under the Causal Markov Assumption, the Strong Causal Faithfulness Assumption, and the assumption of causal suﬃciency, the PC algorithm is a uniformly consistent estimator of the Markov Equivalence Class of the true causal DAG for linear Gaussian models; it follows from this that for the identiﬁable causal effects in the Markov Equivalence Class, there are uniformly consistent estimators of causal eﬀects as well. The k-Triangle-Faithfulness Assumption is a strictly weaker assumption that avoids some implausible implications of the Strong Causal Faithfulness Assumption and also allows for uniformly consistent estimates of Markov Equivalence Classes (in a weakened sense), and of identiﬁable causal effects. However, both of these assumptions are restricted to linear Gaussian models. We propose the Generalized k-Triangle Faithfulness, which can be applied to any smooth distribution. In addition, under the Generalized k-Triangle Faithfulness Assumption, we describe the Edge Estimation Algorithm that provides uniformly consistent estimates of causal eﬀects in some cases (and otherwise outputs “can’t tell”), and the Very Conservative SGS Algorithm that (in a slightly weaker sense) is a uniformly consistent estimator of the Markov equivalence class of the true DAG.},
    language = {en},
    urldate = {2023-02-07},
    publisher = {arXiv},
    author = {Wang, Shuyan and Spirtes, Peter},
    month = jul,
    year = {2021},
    note = {arXiv:2107.01333 [cs, stat]},
    keywords = {Statistics - Methodology, Computer Science - Machine Learning, Statistics - Machine Learning},
    file = {Wang et Spirtes - 2021 - A Uniformly Consistent Estimator of non-Gaussian C.pdf:files/63/Wang et Spirtes - 2021 - A Uniformly Consistent Estimator of non-Gaussian C.pdf:application/pdf},
}

@article{colombo_order-independent_nodate,
    title = {Order-{Independent} {Constraint}-{Based} {Causal} {Structure} {Learning}},
    abstract = {We consider constraint-based methods for causal structure learning, such as the PC-, FCI-, RFCI- and CCD- algorithms (Spirtes et al., 1993, 2000; Richardson, 1996; Colombo et al., 2012; Claassen et al., 2013). The ﬁrst step of all these algorithms consists of the adjacency search of the PC-algorithm. The PC-algorithm is known to be order-dependent, in the sense that the output can depend on the order in which the variables are given. This order-dependence is a minor issue in low-dimensional settings. We show, however, that it can be very pronounced in high-dimensional settings, where it can lead to highly variable results. We propose several modiﬁcations of the PC-algorithm (and hence also of the other algorithms) that remove part or all of this order-dependence. All proposed modiﬁcations are consistent in high-dimensional settings under the same conditions as their original counterparts. We compare the PC-, FCI-, and RFCI-algorithms and their modiﬁcations in simulation studies and on a yeast gene expression data set. We show that our modiﬁcations yield similar performance in low-dimensional settings and improved performance in high-dimensional settings. All software is implemented in the R-package pcalg.},
    language = {en},
    author = {Colombo, Diego and Maathuis, Marloes H},
    file = {Colombo et Maathuis - Order-Independent Constraint-Based Causal Structur.pdf:files/65/Colombo et Maathuis - Order-Independent Constraint-Based Causal Structur.pdf:application/pdf},
}


@article{yu_bionic_2019,
	title = {A bionic robot navigation algorithm based on cognitive mechanism of hippocampus},
	volume = {16},
	number = {4},
	journal = {IEEE Transactions on Automation Science and Engineering},
	author = {Yu, Naigong and Zhai, Yujia and Yuan, Yunhe and Wang, Zongxia},
	year = {2019},
	note = {Publisher: IEEE},
	pages = {1640--1652},
}

@article{gao_overview_2019,
	title = {An overview of biomimetic robots with animal behaviors},
	volume = {332},
	journal = {Neurocomputing},
	author = {Gao, Zihang and Shi, Qing and Fukuda, Toshio and Li, Chang and Huang, Qiang},
	year = {2019},
	note = {Publisher: Elsevier},
	pages = {339--350},
}

@article{schneider_enabling_2020,
	title = {Enabling cognitive behavior of humans, animals, and machines: {A} situation model framework},
	volume = {1},
	journal = {ZiF-Mitteilungen},
	author = {Schneider, Werner X and Albert, Josefine and Ritter, Helge},
	year = {2020},
	pages = {21--34},
}

@inproceedings{balakrishnan_computational_2022,
	title = {A computational model of rodent spatial learning and some behavioral experiments},
	booktitle = {Proceedings of the {Twentieth} {Annual} {Meeting} of the {Cognitive} {Science} {Society}},
	author = {Balakrishnan, Karthik and Bhatt, Rushi and Honavar, Vasant},
	year = {2022},
	pages = {102--107},
}

@article{yu_neuroslam_2019,
	title = {{NeuroSLAM}: a brain-inspired {SLAM} system for {3D} environments},
	volume = {113},
	journal = {Biological cybernetics},
	author = {Yu, Fangwen and Shang, Jianga and Hu, Youjian and Milford, Michael},
	year = {2019},
	note = {Publisher: Springer},
	pages = {515--545},
}

@article{savelli_origin_2019,
	title = {Origin and role of path integration in the cognitive representations of the hippocampus: computational insights into open questions},
	volume = {222},
	number = {Suppl\_1},
	journal = {Journal of Experimental Biology},
	author = {Savelli, Francesco and Knierim, James J},
	year = {2019},
	note = {Publisher: The Company of Biologists Ltd},
	pages = {jeb188912},
}

@article{garg_where_2021,
	title = {Where is your place, visual place recognition?},
	journal = {arXiv preprint arXiv:2103.06443},
	author = {Garg, Sourav and Fischer, Tobias and Milford, Michael},
	year = {2021},
}

@article{taylor_active_2021,
	title = {Active learning in robotics: {A} review of control principles},
	volume = {77},
	journal = {Mechatronics},
	author = {Taylor, Annalisa T and Berrueta, Thomas A and Murphey, Todd D},
	year = {2021},
	note = {Publisher: Elsevier},
	pages = {102576},
}

@article{peng_learning_2020,
	title = {Learning agile robotic locomotion skills by imitating animals},
	journal = {arXiv preprint arXiv:2004.00784},
	author = {Peng, Xue Bin and Coumans, Erwin and Zhang, Tingnan and Lee, Tsang-Wei and Tan, Jie and Levine, Sergey},
	year = {2020},
}

@article{poulter_neurobiology_2018,
	title = {The neurobiology of mammalian navigation},
	volume = {28},
	number = {17},
	journal = {Current Biology},
	author = {Poulter, Steven and Hartley, Tom and Lever, Colin},
	year = {2018},
	note = {Publisher: Elsevier},
	pages = {R1023--R1042},
}

@article{rosinol_kimera_2021,
	title = {Kimera: {From} {SLAM} to spatial perception with {3D} dynamic scene graphs},
	volume = {40},
	number = {12-14},
	journal = {The International Journal of Robotics Research},
	author = {Rosinol, Antoni and Violette, Andrew and Abate, Marcus and Hughes, Nathan and Chang, Yun and Shi, Jingnan and Gupta, Arjun and Carlone, Luca},
	year = {2021},
	note = {Publisher: SAGE Publications Sage UK: London, England},
	pages = {1510--1546},
}

@incollection{brooks_intelligence_2018,
	title = {Intelligence without reason},
	booktitle = {The artificial life route to artificial intelligence},
	publisher = {Routledge},
	author = {Brooks, Rodney A},
	year = {2018},
	pages = {25--81},
}

@article{tang_multiple_2021,
	title = {Multiple time-scales of decision-making in the hippocampus and prefrontal cortex},
	volume = {10},
	journal = {Elife},
	author = {Tang, Wenbo and Shin, Justin D and Jadhav, Shantanu P},
	year = {2021},
	note = {Publisher: eLife Sciences Publications, Ltd},
	pages = {e66227},
}

@article{behrens_what_2018,
	title = {What is a cognitive map? {Organizing} knowledge for flexible behavior},
	volume = {100},
	number = {2},
	journal = {Neuron},
	author = {Behrens, Timothy EJ and Muller, Timothy H and Whittington, James CR and Mark, Shirley and Baram, Alon B and Stachenfeld, Kimberly L and Kurth-Nelson, Zeb},
	year = {2018},
	note = {Publisher: Elsevier},
	pages = {490--509},
}

